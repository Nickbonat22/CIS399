{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"rf_assignment_w19.ipynb","version":"0.3.2","provenance":[],"collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3"}},"cells":[{"metadata":{"id":"_zyEMPhCnHC_","colab_type":"text"},"cell_type":"markdown","source":["<h1>\n","<center>\n","Module 6: Random Forests\n","</center>\n","</h1>\n","<div class=h1_cell>\n","\n","You will be working with the loan table again.\n","\n","</div>"]},{"metadata":{"id":"KJT0kc6FhooT","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":34},"outputId":"517e52ce-70fa-40b9-8d70-8c8a95c7a9c5","executionInfo":{"status":"ok","timestamp":1550518616151,"user_tz":480,"elapsed":428,"user":{"displayName":"Nicholas Bonat","photoUrl":"https://lh5.googleusercontent.com/-Q-bFxRhEAJo/AAAAAAAAAAI/AAAAAAAAAFM/FPsWH90byZ0/s64/photo.jpg","userId":"04391020366496854291"}}},"cell_type":"code","source":["import pandas as pd\n","\n","from google.colab import drive\n","drive.mount('/content/gdrive')"],"execution_count":2,"outputs":[{"output_type":"stream","text":["Drive already mounted at /content/gdrive; to attempt to forcibly remount, call drive.mount(\"/content/gdrive\", force_remount=True).\n"],"name":"stdout"}]},{"metadata":{"id":"YRgA76lahpmR","colab_type":"code","colab":{}},"cell_type":"code","source":["with open('/content/gdrive/My Drive/class_tables/loan_table_week4.csv', 'r') as f:\n","  loan_table = pd.read_csv(f)"],"execution_count":0,"outputs":[]},{"metadata":{"id":"RjDDjSE-htzN","colab_type":"code","colab":{}},"cell_type":"code","source":["!rm library_w19_week6.py"],"execution_count":0,"outputs":[]},{"metadata":{"id":"SCblsgv0nHDB","colab_type":"code","outputId":"c3ff7fff-4e2f-4844-fe56-f10eb594d407","executionInfo":{"status":"ok","timestamp":1550518625978,"user_tz":480,"elapsed":6173,"user":{"displayName":"Nicholas Bonat","photoUrl":"https://lh5.googleusercontent.com/-Q-bFxRhEAJo/AAAAAAAAAAI/AAAAAAAAAFM/FPsWH90byZ0/s64/photo.jpg","userId":"04391020366496854291"}},"colab":{"resources":{"http://localhost:8080/nbextensions/google.colab/files.js":{"data":"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","ok":true,"headers":[["content-type","application/javascript"]],"status":200,"status_text":""}},"base_uri":"https://localhost:8080/","height":108}},"cell_type":"code","source":["from google.colab import files\n","files.upload()"],"execution_count":5,"outputs":[{"output_type":"display_data","data":{"text/html":["\n","     <input type=\"file\" id=\"files-aef77539-bdb4-4620-8f5a-a71365d74f7d\" name=\"files[]\" multiple disabled />\n","     <output id=\"result-aef77539-bdb4-4620-8f5a-a71365d74f7d\">\n","      Upload widget is only available when the cell has been executed in the\n","      current browser session. Please rerun this cell to enable.\n","      </output>\n","      <script src=\"/nbextensions/google.colab/files.js\"></script> "],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{"tags":[]}},{"output_type":"stream","text":["Saving library_w19_week6.py to library_w19_week6.py\n"],"name":"stdout"},{"output_type":"execute_result","data":{"text/plain":["{'library_w19_week6.py': b'import pandas as pd\\nimport numpy as np\\nfrom functools import reduce\\nfrom types import SimpleNamespace\\nimport random\\n\\ndef predictor_case(row, pred, target):\\n\\tcase_dict = {(0,0): \\'true_negative\\', (1,1): \\'true_positive\\', (0,1): \\'false_negative\\', (1,0): \\'false_positive\\'}\\n\\tactual = row[target]\\n\\tprediction = row[pred]\\n\\tcase = case_dict[(prediction, actual)]\\n\\treturn case\\n\\ndef accuracy(cases):\\n\\n    tp = 0\\n    if \\'true_positive\\' in cases:\\n        tp = cases[\\'true_positive\\']\\n    tn = 0\\n    if \\'true_negative\\' in cases:\\n        tn = cases[\\'true_negative\\']\\n    fp = 0\\n    if \\'false_positive\\' in cases:\\n        fp = cases[\\'false_positive\\']\\n    fn = 0\\n    if \\'false_negative\\' in cases:\\n        fn = cases[\\'false_negative\\']\\n\\n    if(tp+tn+fp+fn) == 0:\\n        return 0\\n\\n    return (tp + tn)/(tp+tn+fp+fn)\\n\\n#accuracy(p1_types)\\n\\ndef f1(cases):\\n\\n    #the heart of the matrix\\n    #the heart of the matrix\\n    tp = 0\\n    if \\'true_positive\\' in cases:\\n        tp = cases[\\'true_positive\\']\\n    tn = 0\\n    if \\'true_negative\\' in cases:\\n        tn = cases[\\'true_negative\\']\\n    fp = 0\\n    if \\'false_positive\\' in cases:\\n        fp = cases[\\'false_positive\\']\\n    fn = 0\\n    if \\'false_negative\\' in cases:\\n        fn = cases[\\'false_negative\\']\\n\\n    #other measures we can derive\\n    if (((tp+fn) == 0) or ((tp+fp) == 0)):\\n        return 0\\n    else:\\n        recall = 1.0*tp/(tp+fn)\\n        precision = 1.0*tp/(tp+fp)\\n\\n    #now for the one we want\\n    if ((recall == 0) or (precision == 0)):\\n        return 0\\n    else:\\n        f1 = 2/(1/recall + 1/precision)\\n\\n    return f1\\n\\ndef informedness(cases):\\n\\n    tp = 0\\n    if \\'true_positive\\' in cases:\\n        tp = cases[\\'true_positive\\']\\n    tn = 0\\n    if \\'true_negative\\' in cases:\\n        tn = cases[\\'true_negative\\']\\n    fp = 0\\n    if \\'false_positive\\' in cases:\\n        fp = cases[\\'false_positive\\']\\n    fn = 0\\n    if \\'false_negative\\' in cases:\\n        fn = cases[\\'false_negative\\']\\n    if (((tp+fn) == 0) or ((tn+fp) == 0)):\\n        return 0\\n    else:\\n        recall = 1.0*tp/(tp+fn)\\n        specificity = 1.0*tn/(tn+fp)\\n        J = (recall + specificity) - 1\\n\\n    return J\\n\\ndef gig(starting_table, split_column, target_column):\\n\\n    #split into two branches, i.e., two sub-tables\\n    true_table = starting_table.loc[starting_table[split_column] == 1]\\n    false_table = starting_table.loc[starting_table[split_column] == 0]\\n\\n    #Now see how the target column is divided up in each sub-table (and the starting table)\\n    true_counts = true_table[target_column].value_counts()  # Note using true_table and not starting_table\\n    false_counts = false_table[target_column].value_counts()  # Note using false_table and not starting_table\\n    starting_counts = starting_table[target_column].value_counts()\\n\\n    #compute the gini impurity for the 3 tables\\n    starting_gini = gini(starting_counts)\\n    true_gini = gini(true_counts)\\n    false_gini = gini(false_counts)\\n\\n    #compute the weights\\n    starting_size = len(starting_table.index)\\n    true_weight = 0.0 if starting_size == 0 else len(true_table.index)/starting_size\\n    false_weight = 0.0 if starting_size == 0 else len(false_table.index)/starting_size\\n\\n    #wrap it up and put on a bow\\n    gig = starting_gini - (true_weight * true_gini + false_weight * false_gini)\\n\\n    return gig\\n\\ndef gini(counts):\\n    (p0,p1) = probabilities(counts)\\n    sum_probs = p0**2 + p1**2\\n    gini = 1 - sum_probs\\n    return gini\\n\\ndef probabilities(counts):\\n    count_0 = 0 if 0 not in counts else counts[0]  #could have no 0 values\\n    count_1 = 0 if 1 not in counts else counts[1]\\n    total = count_0 + count_1\\n    probs = (0,0) if total == 0 else (count_0/total, count_1/total)  #build 2-tuple\\n    return probs\\n\\ndef build_pred(column, branch):\\n    return lambda row: row[column] == branch\\n\\ndef find_best_splitter(table, choice_list, target):\\n  \\n    assert (len(table)>0),\"Cannot split empty table\"\\n    assert (target in table),\"Target must be column in table\"\\n    \\n    gig_scores = map(lambda col: (col, gig(table, col, target)), choice_list)  #compute tuple (col, gig) for each column\\n    gig_sorted = sorted(gig_scores, key=lambda item: item[1], reverse=True)  # sort on gig\\n    return gig_sorted\\n\\nfrom functools import reduce\\n\\ndef generate_table(table, conjunction):\\n  \\n    assert (len(table)>0),\"Cannot generate from empty table\"\\n\\n    sub_table = reduce(lambda subtable, pair: subtable.loc[pair[1]], conjunction, table)\\n    return sub_table\\n\\ndef compute_prediction(table, target):\\n  \\n    assert (len(table)>0),\"Cannot predict from empty table\"\\n    assert (target in table),\"Target must be column in table\"\\n    \\n    counts = table[target].value_counts()  # counts looks like {0: v1, 1: v2}\\n\\n    if 0 not in counts:\\n        prediction = 1\\n    elif 1 not in counts:\\n        prediction = 0\\n    elif counts[1] > counts[0]:  # ties go to 0 (negative)\\n        prediction = 1\\n    else:\\n        prediction = 0\\n\\n    return prediction\\n\\ndef build_tree_iter(table, choices, target, hypers={} ):\\n\\n    assert (len(choices)>0),\"Must have at least one column in choices\"\\n    assert (target in table), \"Target column not in table\"\\n    assert (len(table) > 1), \"Table must have more than 1 row\"\\n    \\n    k = hypers[\\'max-depth\\'] if \\'max-depth\\' in hypers else min(4, len(choices))\\n    gig_cutoff = hypers[\\'gig-cutoff\\'] if \\'gig-cutoff\\' in hypers else 0.0\\n    \\n    def iterative_build(k):\\n        columns_sorted = find_best_splitter(table, choices, target)\\n        (best_column, gig_value) = columns_sorted[0]\\n        \\n        #Note I add _1 or _0 to make it more readable for debugging\\n        current_paths = [{\\'conjunction\\': [(best_column+\\'_1\\', build_pred(best_column, 1))],\\n                          \\'prediction\\': None,\\n                          \\'gig_score\\': gig_value},\\n                         {\\'conjunction\\': [(best_column+\\'_0\\', build_pred(best_column, 0))],\\n                          \\'prediction\\': None,\\n                          \\'gig_score\\': gig_value}\\n                        ]\\n        k -= 1  # we just built a level as seed so subtract 1 from k\\n        tree_paths = []  # add completed paths here\\n        \\n        while k>0:\\n            new_paths = []\\n            for path in current_paths:\\n                old_conjunction = path[\\'conjunction\\']  # a list of (name, lambda)\\n                before_table = generate_table(table, old_conjunction)  #the subtable the current conjunct leads to\\n                columns_sorted = find_best_splitter(before_table, choices, target)\\n                (best_column, gig_value) = columns_sorted[0]\\n                if gig_value > gig_cutoff:\\n                    new_path_1 = {\\'conjunction\\': old_conjunction + [(best_column+\\'_1\\', build_pred(best_column, 1))],\\n                                \\'prediction\\': None,\\n                                 \\'gig_score\\': gig_value}\\n                    new_paths.append( new_path_1 ) #true\\n                    new_path_0 = {\\'conjunction\\': old_conjunction + [(best_column+\\'_0\\', build_pred(best_column, 0))],\\n                                \\'prediction\\': None,\\n                                 \\'gig_score\\': gig_value}\\n                    new_paths.append( new_path_0 ) #false\\n                else:\\n                    #not worth splitting so complete the path with a prediction\\n                    path[\\'prediction\\'] = compute_prediction(before_table, target)\\n                    tree_paths.append(path)\\n            #end for loop\\n            \\n            current_paths = new_paths\\n            if current_paths != []:\\n                k -= 1\\n            else:\\n                break  # nothing left to extend so have copied all paths to tree_paths\\n        #end while loop\\n\\n        #Generate predictions for all paths that have None\\n        for path in current_paths:\\n            conjunction = path[\\'conjunction\\']\\n            before_table = generate_table(table, conjunction)\\n            path[\\'prediction\\'] = compute_prediction(before_table, target)\\n            tree_paths.append(path)\\n        return tree_paths\\n\\n    return {\\'paths\\': iterative_build(k), \\'weight\\': None}\\n\\n\\ndef tree_predictor(row, tree):\\n    \\n    #go through each path, one by one (could use a map instead of for loop?)\\n    for path in tree[\\'paths\\']:\\n        conjuncts = path[\\'conjunction\\']\\n        result = map(lambda tuple: tuple[1](row), conjuncts)  # potential to be parallelized\\n        if all(result):\\n            return path[\\'prediction\\']\\n    raise LookupError(\\'No true paths found for row: \\' + str(row))\\n\\ndef path_id(row, tree):\\n    assert (len(tree[\\'paths\\']) > 0), \"Tree must have at least one path\"\\n    for path in tree[\\'paths\\']:\\n        conjuncts = path[\\'conjunction\\']\\n        result = map(lambda tuple: tuple[1](row), conjuncts)  # potential to be parallelized\\n        if all(result):\\n            return tree[\\'paths\\'].index(path)\\ndef reorder_paths(table, tree):\\n    pcount = table.apply(lambda row: path_id(row, tree), axis=1)\\n    test = pcount.value_counts()\\n    t = sorted(test.items(), key=lambda x: x[1], reverse=True)\\n    new_paths = []\\n    old = tree[\\'paths\\']\\n    for i,j in t:\\n        old1 = old[i]\\n        new_paths.append(old1)\\n\\n    return new_paths\\n\\ndef produce_scores(table, tree, target):\\n    scratch_table = pd.DataFrame(columns=[\\'prediction\\', \\'actual\\'])\\n    scratch_table[\\'prediction\\'] = table.apply(lambda row: tree_predictor(row, tree), axis=1)\\n    scratch_table[\\'actual\\'] = table[target]  # just copy the target column\\n    cases = scratch_table.apply(lambda row: predictor_case(row, pred=\\'prediction\\', target=\\'actual\\'), axis=1)\\n    vc = cases.value_counts()\\n    return [accuracy(vc), f1(vc), informedness(vc)]\\n\\ndef compute_training(slices, left_out):\\n    training_slices = []\\n    for i,slice in enumerate(slices):\\n        if i == left_out:\\n            continue\\n        training_slices.append(slices[i])\\n    return pd.concat(training_slices)  # note we are returning a table (DataFrame)\\n\\ndef k_fold(table, k, target, hypers, candidate_columns):\\n  \\n    #set up the table where we will record fold results\\n    result_columns = [\\'name\\',  \\'accuracy\\', \\'f1\\', \\'informedness\\']\\n    k_fold_results_table = pd.DataFrame(columns=result_columns)\\n    \\n    #generate the slices\\n    total_len = len(table.index)\\n    slice_size = int(total_len/(1.0*k))\\n    slices = []\\n    for i in range(k-1):\\n        a_slice =  table[i*slice_size:(i+1)*slice_size]\\n        slices.append( a_slice )\\n    slices.append( table[(k-1)*slice_size:] )  # whatever is left\\n    \\n    #generate test results\\n    all_scores = []  #keep track of all k results\\n    for i in range(k):\\n        test_table = slices[i]\\n        train_table = compute_training(slices, i)\\n        fold_tree = build_tree_iter(train_table, candidate_columns, target, hypers)  # train\\n        scores = produce_scores(test_table, fold_tree, target)  # test\\n        results_row = {\\'name\\': \\'fold_\\'+str(i), \\'accuracy\\': scores[0], \\'f1\\': scores[1], \\'informedness\\': scores[2]}\\n        k_fold_results_table = k_fold_results_table.append(results_row,ignore_index=True)\\n        all_scores.append(scores)\\n    \\n    #compute average of all folds\\n    avg_scores = tuple(reduce(lambda total, triple: np.add(triple, total), all_scores)/k)\\n    results_row = {\\'name\\': \\'average\\', \\'accuracy\\': avg_scores[0], \\'f1\\': avg_scores[1], \\'informedness\\': avg_scores[2]}\\n    k_fold_results_table = k_fold_results_table.append(results_row,ignore_index=True)\\n    \\n    #note that I add the meta comment as last step to avoid it being wiped out\\n    k_fold_results_table.meta = SimpleNamespace()\\n    k_fold_results_table.meta.hypers  = hypers # adds comment to remind me of hyper params used\\n    \\n    return k_fold_results_table\\n\\n#Determine if slices are mutually exclusive\\ndef verify_unique(slices):\\n    print((\\'total length all slices\\', sum([len(s) for s in slices])))\\n    for i, a_slice in enumerate(slices[:-1]):\\n        a_set = set(a_slice.index)\\n        for j, b_slice in enumerate(slices[i+1:]):\\n            b_set = set(b_slice.index)\\n            int_set = a_set.intersection(b_set)  # should be empty set as result\\n            print((i,j+i+1,int_set))\\n    return None\\n\\ndef k_fold_random(table, k, target, hypers, candidate_columns):\\n  #set up the table where we will record fold results\\n  result_columns = [\\'name\\',  \\'accuracy\\', \\'f1\\', \\'informedness\\']\\n  k_fold_results_table = pd.DataFrame(columns=result_columns)\\n\\n  #generate the slices\\n  table = shuffle(loan_table)\\n  total_len = len(table.index)\\n  split_size = int(total_len/(1.0*k))\\n  slices = []\\n\\n  #generate the slices\\n  for i in range(k-1):\\n    a_slice =  table[i*split_size:(i+1)*split_size]\\n    slices.append( a_slice )\\n  slices.append( table[(k-1)*split_size:] )\\n\\n  verify_unique(slices)  # should see 614 length and empty sets all the way down\\n\\n  #generate test results\\n  all_scores = []  #keep track of all k results\\n  for i in range(k):\\n      test_table = slices[i]\\n      train_table = compute_training(slices, i)\\n      fold_tree = build_tree_iter(train_table, candidate_columns, target, hypers)  # train\\n      scores = produce_scores(test_table, fold_tree, target)  # test\\n      results_row = {\\'name\\': \\'fold_\\'+str(i), \\'accuracy\\': scores[0], \\'f1\\': scores[1], \\'informedness\\': scores[2]}\\n      k_fold_results_table = k_fold_results_table.append(results_row,ignore_index=True)\\n      all_scores.append(scores)\\n\\n  #compute average of all folds\\n  avg_scores = tuple(reduce(lambda total, triple: np.add(triple, total), all_scores)/k)\\n  results_row = {\\'name\\': \\'average\\', \\'accuracy\\': avg_scores[0], \\'f1\\': avg_scores[1], \\'informedness\\': avg_scores[2]}\\n  k_fold_results_table = k_fold_results_table.append(results_row,ignore_index=True)\\n\\n  #note that I add the meta comment as last step to avoid it being wiped out\\n  k_fold_results_table.meta = SimpleNamespace()\\n  k_fold_results_table.meta.hypers  = hypers # adds comment to remind me of hyper params used\\n\\n  return k_fold_results_table\\n\\ndef vote_taker(row, forest):\\n    votes = {0:0, 1:0}\\n    for tree in forest:\\n        prediction = tree_predictor(row, tree)\\n        votes[prediction] += 1\\n    winner = 1 if votes[1]>votes[0] else 0  #ties go to 0\\n    return winner\\n\\ndef forest_scores(table, forest, target):\\n    scratch_table = pd.DataFrame(columns=[\\'prediction\\', \\'actual\\'])\\n    scratch_table[\\'prediction\\'] = table.apply(lambda row: vote_taker(row, forest), axis=1)  #only change is to call vote_taker\\n    scratch_table[\\'actual\\'] = table[target]  # just copy the target column\\n    cases = scratch_table.apply(lambda row: predictor_case(row, pred=\\'prediction\\', target=\\'actual\\'), axis=1)\\n    vc = cases.value_counts()\\n    return [accuracy(vc), f1(vc), informedness(vc)]\\n\\ndef forest_builder(table, column_choices, target, hypers):\\n\\n    tree_n = 5 if \\'total-trees\\' not in hypers else hypers[\\'total-trees\\']\\n    m = int(len(column_choices)**.5) if \\'m\\' not in hypers else hypers[\\'m\\']\\n    k = hypers[\\'max-depth\\'] if \\'max-depth\\' in hypers else min(2, len(column_choices))\\n    gig_cutoff = hypers[\\'gig-cutoff\\'] if \\'gig-cutoff\\' in hypers else 0.0\\n    rgen = hypers[\\'random-state\\'] if \\'random-state\\' in hypers else 0  #an int will work as seed with the sample method.\\n\\n    #build a single tree of depth n - call it multiple times to build multiple trees\\n    def iterative_build(n):\\n        train = table.sample(frac=1.0, replace=True, random_state=rgen)\\n        train = train.reset_index()\\n        left_out = table.loc[~table.index.isin(train[\\'index\\'])]\\n        left_out = left_out.reset_index() # this gives us the old index in its own column\\n        oob_list = left_out[\\'index\\'].tolist()  # list of row indices from original titanic table\\n        \\n        rcols = random.sample(column_choices, m)  # subspcace sampling - uses random.seed, not rng\\n        columns_sorted = find_best_splitter(train, rcols, target)\\n        (best_column, gig_value) = columns_sorted[0]\\n\\n        #Note I add _1 or _0 to make it more readable for debugging\\n        current_paths = [{\\'conjunction\\': [(best_column+\\'_1\\', build_pred(best_column, 1))],\\n                          \\'prediction\\': None,\\n                          \\'gig_score\\': gig_value},\\n                         {\\'conjunction\\': [(best_column+\\'_0\\', build_pred(best_column, 0))],\\n                          \\'prediction\\': None,\\n                          \\'gig_score\\': gig_value}\\n                        ]\\n        n -= 1  # we just built a level as seed so subtract 1 from n\\n        tree_paths = []  # add completed paths here\\n\\n        while n>0:\\n            new_paths = []\\n            for path in current_paths:\\n                conjunct = path[\\'conjunction\\']  # a list of (name, lambda)\\n                before_table = generate_table(train, conjunct)  #the subtable the current conjunct leads to\\n                rcols = random.sample(column_choices, m)  # subspace\\n                columns_sorted = find_best_splitter(before_table, rcols, target)\\n                (best_column, gig_value) = columns_sorted[0]\\n                if gig_value > gig_cutoff:\\n                    new_path_1 = {\\'conjunction\\': conjunct + [(best_column+\\'_1\\', build_pred(best_column, 1))],\\n                                \\'prediction\\': None,\\n                                 \\'gig_score\\': gig_value}\\n                    new_paths.append( new_path_1 ) #true\\n                    new_path_0 = {\\'conjunction\\': conjunct + [(best_column+\\'_0\\', build_pred(best_column, 0))],\\n                                \\'prediction\\': None,\\n                                 \\'gig_score\\': gig_value\\n                                 }\\n                    new_paths.append( new_path_0 ) #false\\n                else:\\n                    #not worth splitting so complete the path with a prediction\\n                    path[\\'prediction\\'] = compute_prediction(before_table, target)\\n                    tree_paths.append(path)\\n            #end for loop\\n\\n            current_paths = new_paths\\n            if current_paths != []:\\n                n -= 1\\n            else:\\n                break  # nothing left to extend so have copied all paths to tree_paths\\n        #end while loop\\n\\n        #Generate predictions for all paths that have None\\n        for path in current_paths:\\n            conjunct = path[\\'conjunction\\']\\n            before_table = generate_table(train, conjunct)\\n            path[\\'prediction\\'] = compute_prediction(before_table, target)\\n            tree_paths.append(path)\\n        return (tree_paths, oob_list)\\n    \\n    #let\\'s build a forest\\n    forest = []\\n    for i in range(tree_n):\\n        (paths, oob) = iterative_build(k)  #always use k for now\\n        forest.append({\\'paths\\': paths, \\'weight\\': None, \\'oob\\': oob})\\n        \\n    return forest\\n'}"]},"metadata":{"tags":[]},"execution_count":5}]},{"metadata":{"id":"rtmSW_2BnHDF","colab_type":"code","outputId":"c31c6117-5afd-4a6a-8812-28ae531928ef","executionInfo":{"status":"ok","timestamp":1550518627998,"user_tz":480,"elapsed":411,"user":{"displayName":"Nicholas Bonat","photoUrl":"https://lh5.googleusercontent.com/-Q-bFxRhEAJo/AAAAAAAAAAI/AAAAAAAAAFM/FPsWH90byZ0/s64/photo.jpg","userId":"04391020366496854291"}},"colab":{"base_uri":"https://localhost:8080/","height":88}},"cell_type":"code","source":["from library_w19_week6 import *\n","\n","%who function"],"execution_count":6,"outputs":[{"output_type":"stream","text":["accuracy\t build_pred\t build_tree_iter\t compute_prediction\t compute_training\t f1\t find_best_splitter\t forest_builder\t forest_scores\t \n","generate_table\t gig\t gini\t informedness\t k_fold\t k_fold_random\t path_id\t predictor_case\t probabilities\t \n","produce_scores\t reorder_paths\t tree_predictor\t verify_unique\t vote_taker\t \n"],"name":"stdout"}]},{"metadata":{"scrolled":true,"id":"YnHkUajjnHDQ","colab_type":"code","outputId":"cae9319e-8380-4b03-be07-2bfdd9152cc2","executionInfo":{"status":"ok","timestamp":1550518629039,"user_tz":480,"elapsed":473,"user":{"displayName":"Nicholas Bonat","photoUrl":"https://lh5.googleusercontent.com/-Q-bFxRhEAJo/AAAAAAAAAAI/AAAAAAAAAFM/FPsWH90byZ0/s64/photo.jpg","userId":"04391020366496854291"}},"colab":{"base_uri":"https://localhost:8080/","height":241}},"cell_type":"code","source":["pd.set_option('display.max_columns', None)\n","loan_table.head()"],"execution_count":7,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>Gender</th>\n","      <th>Married</th>\n","      <th>Dependents</th>\n","      <th>Education</th>\n","      <th>Self_Employed</th>\n","      <th>ApplicantIncome</th>\n","      <th>CoapplicantIncome</th>\n","      <th>LoanAmount</th>\n","      <th>Loan_Amount_Term</th>\n","      <th>Credit_History</th>\n","      <th>Property_Area</th>\n","      <th>Loan_Status</th>\n","      <th>no_lam</th>\n","      <th>filled_lam</th>\n","      <th>pa_Rural</th>\n","      <th>pa_Semiurban</th>\n","      <th>pa_Urban</th>\n","      <th>pa_nan</th>\n","      <th>lam_bin</th>\n","      <th>lam_Low</th>\n","      <th>lam_Average</th>\n","      <th>lam_High</th>\n","      <th>ch_bad</th>\n","      <th>ch_good</th>\n","      <th>ch_nan</th>\n","      <th>apin_binned</th>\n","      <th>apin_low</th>\n","      <th>apin_average</th>\n","      <th>apin_high</th>\n","      <th>apin_nan</th>\n","      <th>dep_0</th>\n","      <th>dep_1</th>\n","      <th>dep_2</th>\n","      <th>dep_3+</th>\n","      <th>dep_nan</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>Male</td>\n","      <td>No</td>\n","      <td>0</td>\n","      <td>Graduate</td>\n","      <td>No</td>\n","      <td>5849</td>\n","      <td>0.0</td>\n","      <td>NaN</td>\n","      <td>360.0</td>\n","      <td>1.0</td>\n","      <td>Urban</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>146.412162</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>Low</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>low</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>Male</td>\n","      <td>Yes</td>\n","      <td>1</td>\n","      <td>Graduate</td>\n","      <td>No</td>\n","      <td>4583</td>\n","      <td>1508.0</td>\n","      <td>128.0</td>\n","      <td>360.0</td>\n","      <td>1.0</td>\n","      <td>Rural</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>128.000000</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>Low</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>low</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>Male</td>\n","      <td>Yes</td>\n","      <td>0</td>\n","      <td>Graduate</td>\n","      <td>Yes</td>\n","      <td>3000</td>\n","      <td>0.0</td>\n","      <td>66.0</td>\n","      <td>360.0</td>\n","      <td>1.0</td>\n","      <td>Urban</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>66.000000</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>Low</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>low</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>Male</td>\n","      <td>Yes</td>\n","      <td>0</td>\n","      <td>Not Graduate</td>\n","      <td>No</td>\n","      <td>2583</td>\n","      <td>2358.0</td>\n","      <td>120.0</td>\n","      <td>360.0</td>\n","      <td>1.0</td>\n","      <td>Urban</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>120.000000</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>Low</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>low</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>Male</td>\n","      <td>No</td>\n","      <td>0</td>\n","      <td>Graduate</td>\n","      <td>No</td>\n","      <td>6000</td>\n","      <td>0.0</td>\n","      <td>141.0</td>\n","      <td>360.0</td>\n","      <td>1.0</td>\n","      <td>Urban</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>141.000000</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>Low</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>low</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["  Gender Married Dependents     Education Self_Employed  ApplicantIncome  \\\n","0   Male      No          0      Graduate            No             5849   \n","1   Male     Yes          1      Graduate            No             4583   \n","2   Male     Yes          0      Graduate           Yes             3000   \n","3   Male     Yes          0  Not Graduate            No             2583   \n","4   Male      No          0      Graduate            No             6000   \n","\n","   CoapplicantIncome  LoanAmount  Loan_Amount_Term  Credit_History  \\\n","0                0.0         NaN             360.0             1.0   \n","1             1508.0       128.0             360.0             1.0   \n","2                0.0        66.0             360.0             1.0   \n","3             2358.0       120.0             360.0             1.0   \n","4                0.0       141.0             360.0             1.0   \n","\n","  Property_Area  Loan_Status  no_lam  filled_lam  pa_Rural  pa_Semiurban  \\\n","0         Urban            1       1  146.412162         0             0   \n","1         Rural            0       0  128.000000         1             0   \n","2         Urban            1       0   66.000000         0             0   \n","3         Urban            1       0  120.000000         0             0   \n","4         Urban            1       0  141.000000         0             0   \n","\n","   pa_Urban  pa_nan lam_bin  lam_Low  lam_Average  lam_High  ch_bad  ch_good  \\\n","0         1       0     Low        1            0         0       0        1   \n","1         0       0     Low        1            0         0       0        1   \n","2         1       0     Low        1            0         0       0        1   \n","3         1       0     Low        1            0         0       0        1   \n","4         1       0     Low        1            0         0       0        1   \n","\n","   ch_nan apin_binned  apin_low  apin_average  apin_high  apin_nan  dep_0  \\\n","0       0         low         1             0          0         0      1   \n","1       0         low         1             0          0         0      0   \n","2       0         low         1             0          0         0      1   \n","3       0         low         1             0          0         0      1   \n","4       0         low         1             0          0         0      1   \n","\n","   dep_1  dep_2  dep_3+  dep_nan  \n","0      0      0       0        0  \n","1      1      0       0        0  \n","2      0      0       0        0  \n","3      0      0       0        0  \n","4      0      0       0        0  "]},"metadata":{"tags":[]},"execution_count":7}]},{"metadata":{"id":"gVKmmwDqnHDW","colab_type":"code","outputId":"3dab87aa-bc55-451d-9a39-e2b982d5c1ae","executionInfo":{"status":"ok","timestamp":1550518631533,"user_tz":480,"elapsed":352,"user":{"displayName":"Nicholas Bonat","photoUrl":"https://lh5.googleusercontent.com/-Q-bFxRhEAJo/AAAAAAAAAAI/AAAAAAAAAFM/FPsWH90byZ0/s64/photo.jpg","userId":"04391020366496854291"}},"colab":{"base_uri":"https://localhost:8080/","height":153}},"cell_type":"code","source":["loan_table.columns.values"],"execution_count":8,"outputs":[{"output_type":"execute_result","data":{"text/plain":["array(['Gender', 'Married', 'Dependents', 'Education', 'Self_Employed',\n","       'ApplicantIncome', 'CoapplicantIncome', 'LoanAmount',\n","       'Loan_Amount_Term', 'Credit_History', 'Property_Area',\n","       'Loan_Status', 'no_lam', 'filled_lam', 'pa_Rural', 'pa_Semiurban',\n","       'pa_Urban', 'pa_nan', 'lam_bin', 'lam_Low', 'lam_Average',\n","       'lam_High', 'ch_bad', 'ch_good', 'ch_nan', 'apin_binned',\n","       'apin_low', 'apin_average', 'apin_high', 'apin_nan', 'dep_0',\n","       'dep_1', 'dep_2', 'dep_3+', 'dep_nan'], dtype=object)"]},"metadata":{"tags":[]},"execution_count":8}]},{"metadata":{"id":"VpXRjQHtnHDa","colab_type":"text"},"cell_type":"markdown","source":["<hr>\n","<h1>\n","1: Explore forest options (20)\n","</h1>\n","<p>\n","<div class=h1_cell>\n","<p>\n","Check out the results you get from forests of size 5, 11, 17.\n","<p>\n","First, define the columns to use. I do that for you below.\n","</div>"]},{"metadata":{"id":"DNRyB8DvnHDc","colab_type":"code","colab":{}},"cell_type":"code","source":["splitter_columns = [\n","        #Dependents\n","        'dep_0', 'dep_1', 'dep_2', 'dep_3+',\n","        #ApplicantIncome\n","       'apin_low', 'apin_high', 'apin_average',\n","        #Property_Area\n","        'pa_Rural', 'pa_Semiurban','pa_Urban',\n","        #LoanAmount\n","        'lam_Low', 'lam_Average', 'lam_High',\n","        #Credit_History\n","        'ch_bad', 'ch_good']"],"execution_count":0,"outputs":[]},{"metadata":{"id":"zPLu2ub9nHDg","colab_type":"text"},"cell_type":"markdown","source":["<hr>\n","<h2>\n","Set seeds so get consistent results\n","</h2>\n","<p>\n","<div class=h1_cell>\n","<p>\n","\n","</div>"]},{"metadata":{"id":"W1eNjUiSnW0p","colab_type":"code","colab":{}},"cell_type":"code","source":["import numpy as np\n","import random\n","\n","rng = np.random.RandomState(42)  #Will pass as arg to pandas sample method\n","random.seed(2000)"],"execution_count":0,"outputs":[]},{"metadata":{"id":"iuhvnqw3nHDh","colab_type":"code","outputId":"359860ad-00b6-4ce6-8f09-954ac8f30cce","executionInfo":{"status":"ok","timestamp":1550518636118,"user_tz":480,"elapsed":550,"user":{"displayName":"Nicholas Bonat","photoUrl":"https://lh5.googleusercontent.com/-Q-bFxRhEAJo/AAAAAAAAAAI/AAAAAAAAAFM/FPsWH90byZ0/s64/photo.jpg","userId":"04391020366496854291"}},"colab":{"base_uri":"https://localhost:8080/","height":34}},"cell_type":"code","source":["forest1 = forest_builder(loan_table, splitter_columns, 'Loan_Status', hypers={'total-trees': 5, 'random-state': rng})\n","len(forest1)"],"execution_count":11,"outputs":[{"output_type":"execute_result","data":{"text/plain":["5"]},"metadata":{"tags":[]},"execution_count":11}]},{"metadata":{"id":"-fCS27OonHDm","colab_type":"code","outputId":"819d9de5-f9ef-4c62-fcb4-65e23951cc7d","executionInfo":{"status":"ok","timestamp":1550518637038,"user_tz":480,"elapsed":501,"user":{"displayName":"Nicholas Bonat","photoUrl":"https://lh5.googleusercontent.com/-Q-bFxRhEAJo/AAAAAAAAAAI/AAAAAAAAAFM/FPsWH90byZ0/s64/photo.jpg","userId":"04391020366496854291"}},"colab":{"base_uri":"https://localhost:8080/","height":34}},"cell_type":"code","source":["forest_scores(loan_table, forest1, 'Loan_Status')\n"],"execution_count":12,"outputs":[{"output_type":"execute_result","data":{"text/plain":["[0.8094462540716613, 0.8764519535374868, 0.4104956556082149]"]},"metadata":{"tags":[]},"execution_count":12}]},{"metadata":{"id":"Rjc3x2M8nHDr","colab_type":"code","outputId":"7be4ad04-7a71-48b3-cd9a-da8e385ce104","executionInfo":{"status":"ok","timestamp":1550518639536,"user_tz":480,"elapsed":763,"user":{"displayName":"Nicholas Bonat","photoUrl":"https://lh5.googleusercontent.com/-Q-bFxRhEAJo/AAAAAAAAAAI/AAAAAAAAAFM/FPsWH90byZ0/s64/photo.jpg","userId":"04391020366496854291"}},"colab":{"base_uri":"https://localhost:8080/","height":34}},"cell_type":"code","source":["forest2 = forest_builder(loan_table, splitter_columns, 'Loan_Status', hypers={'total-trees': 11, 'random-state': rng})\n","len(forest2)"],"execution_count":13,"outputs":[{"output_type":"execute_result","data":{"text/plain":["11"]},"metadata":{"tags":[]},"execution_count":13}]},{"metadata":{"id":"IXRcCWcpnHDx","colab_type":"code","outputId":"84e70c62-a71e-45ed-a9af-937e07170794","executionInfo":{"status":"ok","timestamp":1550518640317,"user_tz":480,"elapsed":717,"user":{"displayName":"Nicholas Bonat","photoUrl":"https://lh5.googleusercontent.com/-Q-bFxRhEAJo/AAAAAAAAAAI/AAAAAAAAAFM/FPsWH90byZ0/s64/photo.jpg","userId":"04391020366496854291"}},"colab":{"base_uri":"https://localhost:8080/","height":34}},"cell_type":"code","source":["forest_scores(loan_table, forest2, 'Loan_Status')\n"],"execution_count":14,"outputs":[{"output_type":"execute_result","data":{"text/plain":["[0.7785016286644951, 0.8597938144329897, 0.3058599921011058]"]},"metadata":{"tags":[]},"execution_count":14}]},{"metadata":{"id":"I-n4Tf5bnHD2","colab_type":"code","outputId":"04470a25-8d14-4245-f412-02e38f22faec","executionInfo":{"status":"ok","timestamp":1550518641591,"user_tz":480,"elapsed":1046,"user":{"displayName":"Nicholas Bonat","photoUrl":"https://lh5.googleusercontent.com/-Q-bFxRhEAJo/AAAAAAAAAAI/AAAAAAAAAFM/FPsWH90byZ0/s64/photo.jpg","userId":"04391020366496854291"}},"colab":{"base_uri":"https://localhost:8080/","height":34}},"cell_type":"code","source":["forest3 = forest_builder(loan_table, splitter_columns, 'Loan_Status', hypers={'total-trees': 17,'random-state': rng})\n","len(forest3)"],"execution_count":15,"outputs":[{"output_type":"execute_result","data":{"text/plain":["17"]},"metadata":{"tags":[]},"execution_count":15}]},{"metadata":{"id":"Sh3evOrbnHD8","colab_type":"code","outputId":"df5ede3d-7277-4d48-c80b-187d0323e86f","executionInfo":{"status":"ok","timestamp":1550518642174,"user_tz":480,"elapsed":796,"user":{"displayName":"Nicholas Bonat","photoUrl":"https://lh5.googleusercontent.com/-Q-bFxRhEAJo/AAAAAAAAAAI/AAAAAAAAAFM/FPsWH90byZ0/s64/photo.jpg","userId":"04391020366496854291"}},"colab":{"base_uri":"https://localhost:8080/","height":34}},"cell_type":"code","source":["forest_scores(loan_table, forest3, 'Loan_Status')\n"],"execution_count":16,"outputs":[{"output_type":"execute_result","data":{"text/plain":["[0.8094462540716613, 0.8764519535374868, 0.4104956556082149]"]},"metadata":{"tags":[]},"execution_count":16}]},{"metadata":{"id":"cfoOXy5JnHEA","colab_type":"text"},"cell_type":"markdown","source":["<hr>\n","<h1>\n","2: Implement Out of Bag testing (80)\n","</h1>\n","<p>\n","<div class=h1_cell>\n","<p>\n","Last module we looked at the use of K-Folding as a means to test our trees. Random Forests give us an alternative by using out of bag testing. Using notes from the content notebook this week, find a way to do prediction using the oob idea. As reminder, the set union of all the oob lists in a forest make up the testing set. If there is a row in loan_table that is not in any oob list, that row should be omitted from the test set. Further, a tree only gets to vote on a specific row if that row is in the tree's oob list.\n","  <p>\n","  I am going to leave it to you to come up with an algorithm for doing oob testing. If you get totally stuck, I can supply hints. For grading I am looking to make sure you only use oob rows for testing and that each individual tree only votes on rows in its own oob list.\n","    <p>\n","      It is worthwhile solving this problem given something like it will likely be on next midterm.\n","</div>"]},{"metadata":{"id":"QYlMHr1RnHEK","colab_type":"code","colab":{}},"cell_type":"code","source":["def bag_test(forest):\n","  o_list = []\n","  for tree in forest:\n","    o_list += tree['oob']\n","  o_list = list(set(o_list))\n","  testing_table = loan_table.loc[o_list]\n","  testing_table = testing_table.reset_index()\n","  return testing_table\n","\n","def bag_vote_taker(row, forest):\n","  votes = {0:0, 1:0}\n","  for tree in forest:\n","    # check to see if it is in oob\n","    if row['index'] in tree['oob']:\n","      prediction = tree_predictor(row, tree)\n","      votes[prediction] += 1\n","  winner = 1 if votes[1]>votes[0] else 0  #ties go to 0\n","  return winner\n","\n","def bag_forest_scores(table, forest, target):\n","    scratch_table = pd.DataFrame(columns=['prediction', 'actual'])\n","    scratch_table['prediction'] = table.apply(lambda row: bag_vote_taker(row, forest), axis=1)\n","    scratch_table['actual'] = table[target]  # just copy the target column\n","    cases = scratch_table.apply(lambda row: predictor_case(row, pred='prediction', target='actual'), axis=1)\n","    vc = cases.value_counts()\n","    return [accuracy(vc), f1(vc), informedness(vc)]\n"],"execution_count":0,"outputs":[]},{"metadata":{"id":"G9gDrRf8p1E1","colab_type":"text"},"cell_type":"markdown","source":["<h2>Check your oob testing against my results</h2>\n","\n","If you used the random seeds to build your trees, your results should be the same as mine. No randomness during oob testing."]},{"metadata":{"id":"B5PW22KtotRM","colab_type":"code","outputId":"d8853371-bfd2-409c-c635-fbb218ea7cd1","executionInfo":{"status":"ok","timestamp":1550518649839,"user_tz":480,"elapsed":482,"user":{"displayName":"Nicholas Bonat","photoUrl":"https://lh5.googleusercontent.com/-Q-bFxRhEAJo/AAAAAAAAAAI/AAAAAAAAAFM/FPsWH90byZ0/s64/photo.jpg","userId":"04391020366496854291"}},"colab":{"base_uri":"https://localhost:8080/","height":34}},"cell_type":"code","source":["#whole table from above: [0.8094462540716613, 0.8764519535374868, 0.4104956556082149]\n","testing_table_1 = bag_test(forest1)\n","bag_forest_scores(testing_table_1, forest1, 'Loan_Status')\n"],"execution_count":18,"outputs":[{"output_type":"execute_result","data":{"text/plain":["[0.7887067395264117, 0.8595641646489104, 0.39501598819333417]"]},"metadata":{"tags":[]},"execution_count":18}]},{"metadata":{"id":"NeopvaI5psYx","colab_type":"code","colab":{}},"cell_type":"code","source":["testing_table_2 = bag_test(forest2)\n"],"execution_count":0,"outputs":[]},{"metadata":{"id":"Wcj4Oy5vpxlW","colab_type":"code","outputId":"b20c2c14-54d0-4863-c9fe-169ff9d63977","executionInfo":{"status":"ok","timestamp":1550518653627,"user_tz":480,"elapsed":548,"user":{"displayName":"Nicholas Bonat","photoUrl":"https://lh5.googleusercontent.com/-Q-bFxRhEAJo/AAAAAAAAAAI/AAAAAAAAAFM/FPsWH90byZ0/s64/photo.jpg","userId":"04391020366496854291"}},"colab":{"base_uri":"https://localhost:8080/","height":34}},"cell_type":"code","source":["#from above: [0.7785016286644951, 0.8597938144329897, 0.3058599921011058]\n","\n","bag_forest_scores(testing_table_2, forest2, 'Loan_Status')\n"],"execution_count":20,"outputs":[{"output_type":"execute_result","data":{"text/plain":["[0.7586206896551724, 0.8457502623294858, 0.2730153560960946]"]},"metadata":{"tags":[]},"execution_count":20}]},{"metadata":{"id":"ut4tfLw0p-k2","colab_type":"code","colab":{}},"cell_type":"code","source":["testing_table_3 = bag_test(forest3)"],"execution_count":0,"outputs":[]},{"metadata":{"id":"V_bnlpv-p_mm","colab_type":"code","outputId":"0ddd0f26-058d-4027-ac7a-673b5a8416d9","executionInfo":{"status":"ok","timestamp":1550518656802,"user_tz":480,"elapsed":595,"user":{"displayName":"Nicholas Bonat","photoUrl":"https://lh5.googleusercontent.com/-Q-bFxRhEAJo/AAAAAAAAAAI/AAAAAAAAAFM/FPsWH90byZ0/s64/photo.jpg","userId":"04391020366496854291"}},"colab":{"base_uri":"https://localhost:8080/","height":34}},"cell_type":"code","source":["#from above: [0.8094462540716613, 0.8764519535374868, 0.4104956556082149]\n","\n","bag_forest_scores(testing_table_3, forest3, 'Loan_Status')\n"],"execution_count":22,"outputs":[{"output_type":"execute_result","data":{"text/plain":["[0.7768729641693811, 0.8568443051201673, 0.32052231437598744]"]},"metadata":{"tags":[]},"execution_count":22}]},{"metadata":{"id":"9ofRzrrInfGp","colab_type":"text"},"cell_type":"markdown","source":["<h2>Not a lot of change</h2>\n","\n","Using oob testing did not affect scores much. I think we would need to work with bigger tables, e.g., the 25K shelter table, to see a difference."]},{"metadata":{"id":"pqg9TP5Cqpy8","colab_type":"text"},"cell_type":"markdown","source":["<hr>\n","<h1>Write it out</h1>\n","<div class=h1_cell>\n","\n","Did not change table but we did define new functions. Add them to your library as `!rm library_w19_week6b.py`. I added the `b` to designate functions from assignment portion of module.\n","</div>"]}]}